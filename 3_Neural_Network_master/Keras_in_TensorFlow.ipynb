{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version: 3.6.9 (default, Oct  8 2020, 12:12:24) \n",
      "tensorflow version: 2.3.1\n",
      "numpy version: 1.18.5\n",
      "pandas version: 1.1.3\n",
      "matplotlib version: 3.3.2\n",
      "seaborn version: 0.11.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, losses, optimizers, datasets, Sequential\n",
    "\n",
    "print('python version:', sys.version.split('\\n')[0])\n",
    "for m in [tf, np, pd, mpl, sns]:\n",
    "    print(m.__name__, 'version:', m.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.6590012  0.24243298 0.09856589], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([2.,1.,0.1])\n",
    "layer = layers.Softmax(axis=-1)\n",
    "out = layer(x)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.        1.3407786]\n",
      " [0.        1.2194555]\n",
      " [0.        2.016048 ]\n",
      " [0.        1.1010207]], shape=(4, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "network = Sequential([\n",
    "    layers.Dense(3, activation='relu'),\n",
    "    layers.Dense(2, activation='relu')\n",
    "])\n",
    "\n",
    "x = tf.random.normal([4,3])\n",
    "out = network(x)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (4, 3)                    15        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (4, 3)                    12        \n",
      "=================================================================\n",
      "Total params: 27\n",
      "Trainable params: 27\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "dense_2/kernel:0 (4, 3)\n",
      "dense_2/bias:0 (3,)\n",
      "dense_3/kernel:0 (3, 3)\n",
      "dense_3/bias:0 (3,)\n"
     ]
    }
   ],
   "source": [
    "layers_num = 2\n",
    "network = Sequential([])\n",
    "for _ in range(layers_num):\n",
    "    network.add(layers.Dense(3, activation='relu'))\n",
    "network.build(input_shape=(4,4))\n",
    "network.summary()\n",
    "for p in network.trainable_variables:\n",
    "    print(p.name, p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile, Fit and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 784) (20, 10)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 244,522\n",
      "Trainable params: 244,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: -2.2547 - accuracy: 0.0900\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 0s 31ms/step - loss: -76.1927 - accuracy: 0.1500 - val_loss: -18.3756 - val_accuracy: 0.1000\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: -986.3985 - accuracy: 0.1400\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 0s 5ms/step - loss: -7703.3638 - accuracy: 0.1600 - val_loss: 130.1220 - val_accuracy: 0.1000\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 0s 3ms/step - loss: -34662.2148 - accuracy: 0.2200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [-2.254695177078247,\n",
       "  -76.19269561767578,\n",
       "  -986.3984985351562,\n",
       "  -7703.36376953125,\n",
       "  -34662.21484375],\n",
       " 'accuracy': [0.09000000357627869,\n",
       "  0.15000000596046448,\n",
       "  0.14000000059604645,\n",
       "  0.1599999964237213,\n",
       "  0.2199999988079071],\n",
       " 'val_loss': [-18.3756103515625, 130.1220245361328],\n",
       " 'val_accuracy': [0.10000000149011612, 0.10000000149011612]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_db = tf.data.Dataset.from_tensor_slices((tf.random.normal([100, 28*28]), tf.random.normal([100,10]))) \n",
    "train_db = train_db.shuffle(60000).batch(20)\n",
    "val_db = tf.data.Dataset.from_tensor_slices((tf.random.normal([20, 28*28]), tf.random.normal([20,10])))\n",
    "val_db = val_db.batch(20)\n",
    "\n",
    "sample = next(iter(train_db))\n",
    "print(sample[0].shape, sample[1].shape)\n",
    "\n",
    "network = Sequential([\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(10)\n",
    "])\n",
    "network.build(input_shape=(None, 28*28))\n",
    "network.summary()\n",
    "network.compile(\n",
    "    optimizer=optimizers.Adam(lr=0.01),\n",
    "    loss=losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "history = network.fit(train_db, epochs=5, validation_data=val_db, validation_freq=2)\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict x: (20, 784)\n",
      "(20, 10)\n"
     ]
    }
   ],
   "source": [
    "x,y = next(iter(val_db))\n",
    "print('predict x:', x.shape) \n",
    "out = network.predict(x) \n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modle sqve and load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved weights\n"
     ]
    }
   ],
   "source": [
    "network.save_weights('Model/weights.ckpt')\n",
    "print('saved weights')\n",
    "del network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded weights!\n"
     ]
    }
   ],
   "source": [
    "network = Sequential([\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(10)\n",
    "])\n",
    "network.build(input_shape=(None, 28*28))\n",
    "network.compile(\n",
    "    optimizer=optimizers.Adam(lr=0.01),\n",
    "    loss=tf.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "network.load_weights('Model/weights.ckpt')\n",
    "print('loaded weights!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved total model.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "network.save('Model/model.h5')\n",
    "print('saved total model.')\n",
    "del network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "network = keras.models.load_model('Model/model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/thisischixu/env/tf_py3/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/thisischixu/env/tf_py3/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: model-savedmodel/assets\n",
      "saving savedmodel.\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(network, 'model-savedmodel')\n",
    "print('saving savedmodel.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = tf.saved_model.load('model-savedmodel')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
